{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "id": "SOEisyxlh-oi",
        "outputId": "5998b7ac-27a9-465d-bf5e-ebc2fe9a7fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/1h3JmMNvF7pLor34P-qm2FEkIev93euuf/ML_FInal_Project\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1h3JmMNvF7pLor34P-qm2FEkIev93euuf/ML_FInal_Project/wandb/run-20250701_214030-203kqgxf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/203kqgxf' target=\"_blank\">SARIMA_v5_param_changes</a></strong> to <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/203kqgxf' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/203kqgxf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️  Fitting 100 series on -1 cores…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  9.9min\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 15.6min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️  Parallel fitting complete.\n",
            "Drop counts by reason:\n",
            "  ratio_exceeded      : 35\n",
            "  ok                  : 45\n",
            "  low_avg_sales       : 18\n",
            "  insufficient_length : 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>coverage/total_depts</td><td>▁</td></tr><tr><td>coverage/valid</td><td>▁</td></tr><tr><td>metrics/avg_mae</td><td>▁</td></tr><tr><td>metrics/best_mae</td><td>▁</td></tr><tr><td>metrics/median_mae</td><td>▁</td></tr><tr><td>metrics/worst_mae</td><td>▁</td></tr><tr><td>perf/avg_fit_time</td><td>▁</td></tr><tr><td>perf/max_fit_time</td><td>▁</td></tr><tr><td>perf/median_fit_time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>coverage/total_depts</td><td>3331</td></tr><tr><td>coverage/valid</td><td>45</td></tr><tr><td>metrics/avg_mae</td><td>4114.0854</td></tr><tr><td>metrics/best_mae</td><td>547.81974</td></tr><tr><td>metrics/median_mae</td><td>2802.73367</td></tr><tr><td>metrics/worst_mae</td><td>23981.86127</td></tr><tr><td>perf/avg_fit_time</td><td>23.26443</td></tr><tr><td>perf/max_fit_time</td><td>42.96892</td></tr><tr><td>perf/median_fit_time</td><td>27.04476</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SARIMA_v5_param_changes</strong> at: <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/203kqgxf' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/203kqgxf</a><br> View project at: <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250701_214030-203kqgxf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 0. Mount & setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/ML_FInal_Project\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import time\n",
        "import gc\n",
        "import wandb\n",
        "from collections import Counter\n",
        "\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# 1. Initialize W&B\n",
        "wandb.login()\n",
        "run = wandb.init(\n",
        "    project=\"walmart-sales-forecasting\",\n",
        "    entity=\"lkata22-free-university-of-tbilisi-\",\n",
        "    name=\"SARIMA_v5_param_changes\",\n",
        "    group=\"SARIMA\",\n",
        "    config={\n",
        "        \"test_size\": 0.2,\n",
        "        \"min_dept_sales\": 3000,\n",
        "        \"max_mae_ratio\": 0.5,\n",
        "        \"max_depts\": 100,      # for dev\n",
        "        \"n_jobs\": -1,\n",
        "        \"p\": 1, \"d\": 1, \"q\": 1,\n",
        "        \"P\": 0, \"D\": 1, \"Q\": 1, \"s\": 52,\n",
        "        \"maxiter\": 50\n",
        "    }\n",
        ")\n",
        "cfg = wandb.config\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "warnings.simplefilter('ignore', ConvergenceWarning)\n",
        "\n",
        "# 2. Load & merge data\n",
        "train    = pd.read_csv(\"data/train.csv\",   parse_dates=[\"Date\"])\n",
        "features = pd.read_csv(\"data/features.csv\",parse_dates=[\"Date\"])\n",
        "stores   = pd.read_csv(\"data/stores.csv\")\n",
        "\n",
        "df = (\n",
        "    train\n",
        "    .merge(features, on=[\"Store\",\"Date\",\"IsHoliday\"], how=\"left\")\n",
        "    .merge(stores, on=\"Store\", how=\"left\")\n",
        ")\n",
        "\n",
        "# 3. Extract config into locals\n",
        "TEST_SIZE     = cfg.test_size\n",
        "MIN_SALES     = cfg.min_dept_sales\n",
        "MAX_MAE_RATIO = cfg.max_mae_ratio\n",
        "MAX_DEPTS     = int(cfg.max_depts)\n",
        "N_JOBS        = int(cfg.n_jobs)\n",
        "P, D, Q       = int(cfg.p), int(cfg.d), int(cfg.q)\n",
        "sP, sD, sQ, s = int(cfg.P), int(cfg.D), int(cfg.Q), int(cfg.s)\n",
        "MAXITER       = int(cfg.maxiter)\n",
        "\n",
        "# 4. Stationarity test\n",
        "def is_stationary(ts):\n",
        "    if ts.dropna().empty:\n",
        "        return False\n",
        "    return adfuller(ts.dropna())[1] <= 0.05\n",
        "\n",
        "# 5. Top-level fit function with debug reasons\n",
        "def fit_series(args):\n",
        "    store, dept, group = args\n",
        "    ts = (\n",
        "        group.set_index('Date')['Weekly_Sales']\n",
        "             .sort_index().asfreq('W-FRI')\n",
        "             .fillna(method='ffill').fillna(method='bfill')\n",
        "    )\n",
        "    if len(ts) < 52:\n",
        "        return (\"insufficient_length\", None)\n",
        "    avg_sales = ts.mean()\n",
        "    if avg_sales < MIN_SALES:\n",
        "        return (\"low_avg_sales\", None)\n",
        "\n",
        "    split = int(len(ts)*(1-TEST_SIZE))\n",
        "    train_ts, test_ts = ts[:split], ts[split:]\n",
        "\n",
        "    # make stationary if needed\n",
        "    diff_flag = False\n",
        "    if not is_stationary(train_ts):\n",
        "        train_ts = train_ts.diff().dropna()\n",
        "        diff_flag = True\n",
        "\n",
        "    # exogenous\n",
        "    exog_cols = ['Temperature','Fuel_Price','CPI','Unemployment']\n",
        "    exog_train = (\n",
        "        group.set_index('Date')[exog_cols]\n",
        "             .reindex(train_ts.index)\n",
        "             .fillna(method='ffill').fillna(method='bfill')\n",
        "    )\n",
        "    exog_test = (\n",
        "        group.set_index('Date')[exog_cols]\n",
        "             .reindex(test_ts.index)\n",
        "             .fillna(method='ffill').fillna(method='bfill')\n",
        "    )\n",
        "\n",
        "    # fit\n",
        "    try:\n",
        "        t0 = time.time()\n",
        "        model = SARIMAX(\n",
        "            train_ts,\n",
        "            exog=exog_train,\n",
        "            order=(P, D, Q),\n",
        "            seasonal_order=(sP, sD, sQ, s),\n",
        "            enforce_stationarity=False,\n",
        "            enforce_invertibility=False\n",
        "        )\n",
        "        fit = model.fit(disp=False, maxiter=MAXITER, cov_type='none')\n",
        "        fit_time = time.time() - t0\n",
        "    except Exception:\n",
        "        return (\"model_error\", None)\n",
        "\n",
        "    # forecast & invert diff\n",
        "    fc = fit.forecast(steps=len(test_ts), exog=exog_test)\n",
        "    if diff_flag:\n",
        "        fc = train_ts.iloc[-1] + fc.cumsum()\n",
        "\n",
        "    mae   = mean_absolute_error(test_ts, fc)\n",
        "    ratio = mae / avg_sales\n",
        "    if ratio > MAX_MAE_RATIO:\n",
        "        return (\"ratio_exceeded\", None)\n",
        "\n",
        "    # success\n",
        "    result = {\n",
        "        'store': store,\n",
        "        'dept':  dept,\n",
        "        'mae':   mae,\n",
        "        'ratio': ratio,\n",
        "        'avg_sales': avg_sales,\n",
        "        'fit_time': fit_time\n",
        "    }\n",
        "    return (\"ok\", result)\n",
        "\n",
        "# 6. Build args list and dispatch in parallel\n",
        "groups    = list(df.groupby(['Store','Dept']))[:MAX_DEPTS]\n",
        "args_list = [(s,d,g) for (s,d),g in groups]\n",
        "\n",
        "print(f\"▶️  Fitting {len(args_list)} series on {N_JOBS} cores…\")\n",
        "raw_out = Parallel(n_jobs=N_JOBS, verbose=5)(\n",
        "    delayed(fit_series)(arg) for arg in args_list\n",
        ")\n",
        "print(\"✔️  Parallel fitting complete.\")\n",
        "\n",
        "# 7. Separate outcomes and count reasons\n",
        "reasons, payloads = zip(*raw_out)\n",
        "counts = Counter(reasons)\n",
        "print(\"Drop counts by reason:\")\n",
        "for reason, cnt in counts.items():\n",
        "    print(f\"  {reason:20s}: {cnt}\")\n",
        "\n",
        "# 8. Collect only successful results\n",
        "results = [p for r,p in raw_out if r==\"ok\"]\n",
        "\n",
        "if not results:\n",
        "    print(\"⚠️  No successful models. Adjust `min_dept_sales`, `max_mae_ratio`, or inspect drop reasons above.\")\n",
        "else:\n",
        "    maes   = [r['mae'] for r in results]\n",
        "    ratios = [r['ratio'] for r in results]\n",
        "    times  = [r['fit_time'] for r in results]\n",
        "    total  = df.groupby(['Store','Dept']).ngroups\n",
        "\n",
        "    # 9. Log metrics\n",
        "    wandb.log({\n",
        "        \"metrics/avg_mae\":      np.mean(maes),\n",
        "        \"metrics/median_mae\":   np.median(maes),\n",
        "        \"metrics/best_mae\":     np.min(maes),\n",
        "        \"metrics/worst_mae\":    np.max(maes),\n",
        "        \"coverage/valid\":       len(results),\n",
        "        \"coverage/total_depts\": total,\n",
        "        \"perf/avg_fit_time\":    np.mean(times),\n",
        "        \"perf/median_fit_time\": np.median(times),\n",
        "        \"perf/max_fit_time\":    np.max(times)\n",
        "    })\n",
        "\n",
        "    # 10. Plot & log distributions\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.hist(ratios, bins=20, edgecolor='black')\n",
        "    plt.title('MAE / Avg Sales Ratio')\n",
        "    wandb.log({\"error_dist\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.hist(times, bins=20, edgecolor='black')\n",
        "    plt.title('SARIMA Fit Time (s)')\n",
        "    wandb.log({\"fit_time_dist\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "# 11. Finish\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import time\n",
        "import gc\n",
        "import wandb\n",
        "\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
        "\n",
        "from joblib import Parallel, delayed"
      ],
      "metadata": {
        "id": "aR1yBJIgwW9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "run = wandb.init(\n",
        "    project=\"walmart-sales-forecasting\",\n",
        "    entity=\"lkata22-free-university-of-tbilisi-\",\n",
        "    name=\"SARIMA_v4\",\n",
        "    group=\"SARIMA\",\n",
        "    config={\n",
        "        \"test_size\": 0.2,\n",
        "        \"min_dept_sales\": 5000,\n",
        "        \"max_mae_ratio\": 0.3,\n",
        "        \"max_depts\": 100,      # for dev; switch to 3330 for full\n",
        "        \"n_jobs\": -1,          # parallel jobs\n",
        "        \"p\": 1, \"d\": 1, \"q\": 1,\n",
        "        \"P\": 0, \"D\": 1, \"Q\": 1, \"s\": 52,\n",
        "        \"maxiter\": 50\n",
        "    }\n",
        ")\n",
        "cfg = wandb.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "KP-2gMlhwisk",
        "outputId": "7e7e90af-0d6f-4715-999f-90e5798eb212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masurm22\u001b[0m (\u001b[33masurm22-free-university-of-tbilisi-6158\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1h3JmMNvF7pLor34P-qm2FEkIev93euuf/ML_FInal_Project/wandb/run-20250701_211416-sjbfisdt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/sjbfisdt' target=\"_blank\">SARIMA_v4</a></strong> to <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/sjbfisdt' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/sjbfisdt</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter('ignore')\n",
        "warnings.simplefilter('ignore', ConvergenceWarning)\n",
        "\n",
        "# 2. Load & merge data\n",
        "train    = pd.read_csv(\"data/train.csv\",   parse_dates=[\"Date\"])\n",
        "features = pd.read_csv(\"data/features.csv\",parse_dates=[\"Date\"])\n",
        "stores   = pd.read_csv(\"data/stores.csv\")\n",
        "\n",
        "df = (\n",
        "    train\n",
        "    .merge(features, on=[\"Store\",\"Date\",\"IsHoliday\"], how=\"left\")\n",
        "    .merge(stores, on=\"Store\", how=\"left\")\n",
        ")\n",
        "\n",
        "# 3. Engineer global calendar & holiday‐proximity features\n",
        "#    compute sorted list of holidays\n",
        "holidays = sorted(df.loc[df.IsHoliday, \"Date\"].unique())\n",
        "\n",
        "def days_to_next_hol(dt):\n",
        "    # minimal non-negative delta\n",
        "    return min((h - dt).days for h in holidays if h >= dt) if any(h>=dt for h in holidays) else 365\n",
        "\n",
        "def days_since_prev_hol(dt):\n",
        "    past = [h for h in holidays if h <= dt]\n",
        "    return (dt - max(past)).days if past else 365\n",
        "\n",
        "df[\"week_of_year\"] = df.Date.dt.isocalendar().week\n",
        "df[\"month\"]        = df.Date.dt.month\n",
        "df[\"dow_to_hol\"]   = df.Date.apply(days_to_next_hol)\n",
        "df[\"dow_since_hol\"]= df.Date.apply(days_since_prev_hol)\n",
        "\n",
        "# 4. Extract config into locals\n",
        "TEST_SIZE     = cfg.test_size\n",
        "MIN_SALES     = cfg.min_dept_sales\n",
        "MAX_MAE_RATIO = cfg.max_mae_ratio\n",
        "MAX_DEPTS     = int(cfg.max_depts)\n",
        "N_JOBS        = int(cfg.n_jobs)\n",
        "P, D, Q       = int(cfg.p), int(cfg.d), int(cfg.q)\n",
        "sP, sD, sQ, s = int(cfg.P), int(cfg.D), int(cfg.Q), int(cfg.s)\n",
        "MAXITER       = int(cfg.maxiter)\n",
        "\n",
        "# 5. Stationarity test\n",
        "def is_stationary(ts):\n",
        "    if ts.dropna().empty:\n",
        "        return False\n",
        "    return adfuller(ts.dropna())[1] <= 0.05\n",
        "\n",
        "# 6. Top-level fit function\n",
        "def fit_series(args):\n",
        "    store, dept, group = args\n",
        "\n",
        "    # build target series\n",
        "    ts = (\n",
        "        group.set_index('Date')['Weekly_Sales']\n",
        "             .sort_index().asfreq('W-FRI')\n",
        "             .fillna(method='ffill').fillna(method='bfill')\n",
        "    )\n",
        "    if len(ts) < 52 or ts.mean() < MIN_SALES:\n",
        "        return None\n",
        "\n",
        "    # split\n",
        "    split = int(len(ts)*(1-TEST_SIZE))\n",
        "    train_ts, test_ts = ts[:split], ts[split:]\n",
        "    avg_sales = train_ts.mean()\n",
        "\n",
        "    # stationarity\n",
        "    diff_flag = False\n",
        "    if not is_stationary(train_ts):\n",
        "        train_ts = train_ts.diff().dropna()\n",
        "        diff_flag = True\n",
        "\n",
        "    # prepare exogenous: use full ts to compute lags/rollings, then slice\n",
        "    full = group.set_index('Date').reindex(ts.index)\n",
        "    exog = pd.DataFrame(index=ts.index)\n",
        "    # original features\n",
        "    exog[['Temperature','Fuel_Price','CPI','Unemployment',\n",
        "          'week_of_year','month','dow_to_hol','dow_since_hol']] = \\\n",
        "        full[['Temperature','Fuel_Price','CPI','Unemployment',\n",
        "              'week_of_year','month','dow_to_hol','dow_since_hol']]\n",
        "    # lags & rolling\n",
        "    exog['lag_1']   = ts.shift(1)\n",
        "    exog['lag_52']  = ts.shift(52)\n",
        "    exog['roll4_m'] = ts.shift(1).rolling(4).mean()\n",
        "    exog['roll4_s'] = ts.shift(1).rolling(4).std()\n",
        "\n",
        "    # fill missing exogs\n",
        "    exog = exog.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    exog_train = exog.loc[train_ts.index]\n",
        "    exog_test  = exog.loc[test_ts.index]\n",
        "\n",
        "    # fit SARIMAX\n",
        "    t0 = time.time()\n",
        "    try:\n",
        "        model = SARIMAX(\n",
        "            train_ts,\n",
        "            exog=exog_train,\n",
        "            order=(P, D, Q),\n",
        "            seasonal_order=(sP, sD, sQ, s),\n",
        "            enforce_stationarity=False,\n",
        "            enforce_invertibility=False\n",
        "        )\n",
        "        fit = model.fit(disp=False, maxiter=MAXITER, cov_type='none')\n",
        "    except Exception:\n",
        "        return None\n",
        "    fit_time = time.time() - t0\n",
        "\n",
        "    # forecast & invert diff\n",
        "    fc = fit.forecast(steps=len(test_ts), exog=exog_test)\n",
        "    if diff_flag:\n",
        "        fc = train_ts.iloc[-1] + fc.cumsum()\n",
        "\n",
        "    # evaluate\n",
        "    mae   = mean_absolute_error(test_ts, fc)\n",
        "    ratio = mae/avg_sales\n",
        "    if ratio > MAX_MAE_RATIO:\n",
        "        return None\n",
        "\n",
        "    # cleanup\n",
        "    del fit, model\n",
        "    gc.collect()\n",
        "\n",
        "    return {\n",
        "        'store': store,\n",
        "        'dept':  dept,\n",
        "        'mae':   mae,\n",
        "        'ratio': ratio,\n",
        "        'avg_sales': avg_sales,\n",
        "        'fit_time': fit_time\n",
        "    }\n",
        "\n",
        "# 7. Build args & dispatch in parallel with progress\n",
        "groups   = list(df.groupby(['Store','Dept']))[:MAX_DEPTS]\n",
        "args_list= [(s,d,g) for (s,d),g in groups]\n",
        "\n",
        "print(f\"Starting fit of {len(args_list)} series on {N_JOBS} cores…\")\n",
        "results = Parallel(n_jobs=N_JOBS, verbose=5)(\n",
        "    delayed(fit_series)(arg) for arg in args_list\n",
        ")\n",
        "print(\"Parallel fitting done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TkK__y2_wpIS",
        "outputId": "d1c386b0-0dc4-4c6b-f1f6-1bbf6bec7072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fit of 100 series on -1 cores…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel fitting done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.1s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = [r for r in results if r is not None]\n",
        "maes    = [r['mae'] for r in results]\n",
        "ratios  = [r['ratio'] for r in results]\n",
        "times   = [r['fit_time'] for r in results]\n",
        "total   = df.groupby(['Store','Dept']).ngroups\n",
        "\n",
        "# 9. Log to W&B\n",
        "wandb.log({\n",
        "    \"metrics/avg_mae\":      np.mean(maes),\n",
        "    \"metrics/median_mae\":   np.median(maes),\n",
        "    \"metrics/best_mae\":     np.min(maes),\n",
        "    \"metrics/worst_mae\":    np.max(maes),\n",
        "    \"coverage/valid\":       len(results),\n",
        "    \"coverage/total_depts\": total,\n",
        "    \"perf/avg_fit_time\":    np.mean(times),\n",
        "    \"perf/median_fit_time\": np.median(times),\n",
        "    \"perf/max_fit_time\":    np.max(times)\n",
        "})\n",
        "\n",
        "# 10. Plot & log distributions\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(ratios, bins=20, edgecolor='black')\n",
        "plt.title('MAE / Avg Sales Ratio')\n",
        "wandb.log({\"error_dist\": wandb.Image(plt)})\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(times, bins=20, edgecolor='black')\n",
        "plt.title('SARIMA Fit Time (s)')\n",
        "wandb.log({\"fit_time_dist\": wandb.Image(plt)})\n",
        "plt.close()\n",
        "\n",
        "# 11. Finish\n",
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "vxvfuQc2Wi2G",
        "outputId": "62eda06b-1dcc-4e6c-aefa-c76fcbc610b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation minimum which has no identity",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-643313055.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"metrics/avg_mae\"\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"metrics/median_mae\"\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m\"metrics/best_mae\"\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"metrics/worst_mae\"\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"coverage/valid\"\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3040\u001b[0m     \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3041\u001b[0m     \"\"\"\n\u001b[0;32m-> 3042\u001b[0;31m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0m\u001b[1;32m   3043\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2X7XIakXysPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}