{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCIDSeQ75H-f",
        "outputId": "73055fb4-5011-4d67-fd59-dde3d5f6d345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1h3JmMNvF7pLor34P-qm2FEkIev93euuf/ML_FInal_Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/ML_FInal_Project\n",
        "\n",
        "!pip install -q wandb lightgbm scikit-learn pandas numpy matplotlib holidays joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JAtmZWkU7D5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "import os"
      ],
      "metadata": {
        "id": "2jy5rJpNFVv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "597CvII-6Xwj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "8772a199-1955-4e70-db82-3f4262402c1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masurm22\u001b[0m (\u001b[33masurm22-free-university-of-tbilisi-6158\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1h3JmMNvF7pLor34P-qm2FEkIev93euuf/ML_FInal_Project/wandb/run-20250627_124049-us2194nz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/us2194nz' target=\"_blank\">LightGBM_experiment_v4</a></strong> to <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/us2194nz' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/us2194nz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/us2194nz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f7e8efc9ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# wandb.login()\n",
        "\n",
        "# wandb.init(\n",
        "#     project=\"walmart-sales-forecasting\",\n",
        "#     entity=\"lkata22-free-university-of-tbilisi-\",\n",
        "#     name=\"LightGBM_experiment_v4\",\n",
        "#     group=\"LightGBM\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.log({\n",
        "#     \"mae\": mae,\n",
        "#     \"rmse\": rmse,\n",
        "#     \"wmae\": wmae,\n",
        "#     \"regular_mae\": regular_mae,\n",
        "#     \"holiday_mae\": holiday_mae,\n",
        "#     \"holiday_ratio\": holiday_mae / regular_mae,\n",
        "#     \"feature_importance\": wandb.Table(dataframe=pd.DataFrame({\n",
        "#         'feature': model.feature_name(),\n",
        "#         'importance': model.feature_importance()\n",
        "#     }).sort_values('importance', ascending=False))\n",
        "# })\n",
        "\n",
        "# train_pred = model.predict(X_train)\n",
        "# val_pred = model.predict(X_valid)\n",
        "\n",
        "# print(f\"Train MAE: {mean_absolute_error(y_train, train_pred):.2f}\")\n",
        "# print(f\"Valid MAE: {mean_absolute_error(y_valid, val_pred):.2f}\")\n",
        "# print(f\"Gap: {(mean_absolute_error(y_train, train_pred) - mean_absolute_error(y_valid, val_pred)):.2f}\")\n",
        "\n",
        "# joblib.dump(model, \"models/lightgbm_model.pkl\")\n",
        "\n",
        "# artifact = wandb.Artifact(\n",
        "#     name=f\"lightgbm-model-{wandb.run.id}\",\n",
        "#     type=\"model\",\n",
        "#     metadata={\n",
        "#         \"features\": list(X_train.columns),\n",
        "#         \"num_features\": len(X_train.columns),\n",
        "#         \"categorical_features\": list(X_train.select_dtypes('category').columns)\n",
        "#     }\n",
        "# )\n",
        "# artifact.add_file(\"models/lightgbm_model.pkl\")\n",
        "# wandb.log_artifact(artifact)\n",
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "cY7bKxiPIuGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"data\"\n",
        "\n",
        "train_raw = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
        "test_raw = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
        "features_df_raw = pd.read_csv(f\"{DATA_PATH}/features.csv\")\n",
        "stores_df_raw = pd.read_csv(f\"{DATA_PATH}/stores.csv\")\n",
        "\n",
        "merged_train_df = pd.merge(\n",
        "    train_raw,\n",
        "    features_df_raw.drop('IsHoliday', axis=1),\n",
        "    on=['Store', 'Date'], how='left'\n",
        ")\n",
        "df_full_train = pd.merge(merged_train_df, stores_df_raw, on=['Store'], how='left')\n",
        "\n",
        "merged_test_df_initial = pd.merge(\n",
        "    test_raw,\n",
        "    features_df_raw.drop('IsHoliday', axis=1),\n",
        "    on=['Store', 'Date'], how='left'\n",
        ")\n",
        "df_full_test = pd.merge(merged_test_df_initial, stores_df_raw, on=['Store'], how='left')\n",
        "\n",
        "\n",
        "for df in [df_full_train, df_full_test]:\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "\n",
        "\n",
        "max_date = df_full_train['Date'].max()\n",
        "cutoff_date = max_date - pd.Timedelta(weeks=30)\n",
        "\n",
        "train_df_split = df_full_train[df_full_train['Date'] <= cutoff_date].copy()\n",
        "val_df_split   = df_full_train[df_full_train['Date'] >  cutoff_date].copy()\n",
        "\n",
        "X_train = train_df_split.drop('Weekly_Sales', axis=1)\n",
        "y_train = train_df_split['Weekly_Sales']\n",
        "X_val   = val_df_split.drop('Weekly_Sales', axis=1)\n",
        "y_val   = val_df_split['Weekly_Sales']\n",
        "\n",
        "# Prepare inputs for pipeline: drop Date and Id\n",
        "for df in [X_train, X_val]:\n",
        "    df.drop(columns=['Date'], errors='ignore', inplace=True)\n",
        "    if 'Id' in df.columns:\n",
        "        df.drop(columns=['Id'], inplace=True)\n",
        "\n",
        "X_train_for_pipeline = X_train.copy()\n",
        "X_val_for_pipeline   = X_val.copy()\n",
        "\n",
        "\n",
        "class WalmartPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, target_columns=None):\n",
        "        self.label_encoders = {}\n",
        "        self.store_dept_means = {}\n",
        "        self.store_means = {}\n",
        "        self.dept_means = {}\n",
        "        self.global_mean = 0.0\n",
        "        self.numerical_medians = {}\n",
        "        self.target_columns = target_columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        Xc = X.copy()\n",
        "        if y is not None:\n",
        "            self.global_mean = y.mean()\n",
        "            tmp = Xc.copy(); tmp['Weekly_Sales'] = y\n",
        "            tmp['Store'] = tmp['Store'].astype(str).fillna('unknown_store')\n",
        "            tmp['Dept']  = tmp['Dept'].astype(str).fillna('unknown_dept')\n",
        "            self.store_dept_means = tmp.groupby(['Store','Dept'])['Weekly_Sales'].mean().to_dict()\n",
        "            self.store_means      = tmp.groupby('Store')['Weekly_Sales'].mean().to_dict()\n",
        "            self.dept_means       = tmp.groupby('Dept')['Weekly_Sales'].mean().to_dict()\n",
        "\n",
        "        # Fit label encoders\n",
        "        for col in ['Store','Dept','Type']:\n",
        "            le = LabelEncoder()\n",
        "            vals = Xc[col].astype(str).fillna('unknown') if col in Xc else ['unknown']\n",
        "            le.fit(vals)\n",
        "            self.label_encoders[col] = le\n",
        "\n",
        "        # Fit medians\n",
        "        num_cols = ['Temperature','Fuel_Price','CPI','Unemployment','Size'] + [f'MarkDown{i}' for i in range(1,6)]\n",
        "        for col in num_cols:\n",
        "            if col in Xc:\n",
        "                self.numerical_medians[col] = Xc[col].median() if not Xc[col].isnull().all() else 0.0\n",
        "            else:\n",
        "                self.numerical_medians[col] = 0.0\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        Xc = X.copy()\n",
        "        # Date features\n",
        "        if 'Date' in Xc:\n",
        "            Xc['Date']=pd.to_datetime(Xc['Date'])\n",
        "            Xc['Year']=Xc['Date'].dt.year; Xc['Month']=Xc['Date'].dt.month\n",
        "            Xc['Week']=Xc['Date'].dt.isocalendar().week.astype(int)\n",
        "            Xc['DayOfYear']=Xc['Date'].dt.dayofyear; Xc['Quarter']=Xc['Date'].dt.quarter\n",
        "            Xc['Month_sin']=np.sin(2*np.pi*Xc['Month']/12)\n",
        "            Xc['Month_cos']=np.cos(2*np.pi*Xc['Month']/12)\n",
        "            Xc['Week_sin']=np.sin(2*np.pi*Xc['Week']/52)\n",
        "            Xc['Week_cos']=np.cos(2*np.pi*Xc['Week']/52)\n",
        "            Xc.drop('Date',axis=1,inplace=True)\n",
        "\n",
        "        # Impute numeric\n",
        "        for col, med in self.numerical_medians.items():\n",
        "            Xc[col] = Xc.get(col, pd.Series([np.nan]*len(Xc))).fillna(med)\n",
        "\n",
        "        # Interaction features\n",
        "        Xc['Store_str']=Xc['Store'].astype(str);\n",
        "        Xc['Dept_str']=Xc['Dept'].astype(str)\n",
        "        Xc['Store_Dept_Mean_Sales'] = Xc.apply(\n",
        "            lambda r: self.store_dept_means.get((r['Store_str'],r['Dept_str']), self.global_mean), axis=1\n",
        "        )\n",
        "        Xc['Store_Mean_Sales']=Xc['Store_str'].map(self.store_means).fillna(self.global_mean)\n",
        "        Xc['Dept_Mean_Sales']=Xc['Dept_str'].map(self.dept_means).fillna(self.global_mean)\n",
        "        Xc.drop(['Store_str','Dept_str'],axis=1,inplace=True)\n",
        "        Xc['Sales_per_Size'] = Xc['Store_Mean_Sales'] / (Xc['Size']+1e-6)\n",
        "\n",
        "        # Holiday interactions\n",
        "        if 'IsHoliday' in Xc:\n",
        "            Xc['IsHoliday_int'] = Xc['IsHoliday'].astype(int)\n",
        "            Xc['Holiday_Dept'] = Xc['IsHoliday_int'] * Xc['Dept'].astype(float)\n",
        "            Xc['Holiday_Store']= Xc['IsHoliday_int'] * Xc['Store'].astype(float)\n",
        "            Xc.drop('IsHoliday_int',axis=1,inplace=True)\n",
        "        else:\n",
        "            Xc['Holiday_Dept']=0.0; Xc['Holiday_Store']=0.0\n",
        "\n",
        "        # Encode categoricals\n",
        "        for col, le in self.label_encoders.items():\n",
        "            vals = Xc[col].astype(str).fillna('unknown')\n",
        "            unseen = ~vals.isin(le.classes_)\n",
        "            if unseen.any(): vals.loc[unseen]='unknown'\n",
        "            Xc[col] = le.transform(vals).astype(int)\n",
        "\n",
        "        # Drop target if present\n",
        "        Xc.drop('Weekly_Sales', axis=1, errors='ignore', inplace=True)\n",
        "\n",
        "        # Final column selection\n",
        "        if self.target_columns:\n",
        "            for c in set(self.target_columns)-set(Xc.columns): Xc[c]=0.0\n",
        "            Xc = Xc[self.target_columns]\n",
        "            # Ensure ints\n",
        "            for c in ['Store','Dept','Type','Year','Month','Week','DayOfYear','Quarter']:\n",
        "                if c in Xc: Xc[c]=Xc[c].astype(int)\n",
        "            # Floats\n",
        "            for c in Xc.columns:\n",
        "                if pd.api.types.is_numeric_dtype(Xc[c]) and not pd.api.types.is_integer_dtype(Xc[c]):\n",
        "                    Xc[c]=Xc[c].astype(float)\n",
        "        return Xc\n",
        "\n",
        "\n",
        "class LightGBMRegressor(BaseEstimator):\n",
        "    def __init__(self, **params):\n",
        "        self.params = {\n",
        "            'objective':'regression','metric':'mae','boosting_type':'gbdt',\n",
        "            'num_leaves':64,'learning_rate':0.05,'feature_fraction':0.8,\n",
        "            'bagging_fraction':0.8,'bagging_freq':5,'min_child_samples':20,\n",
        "            'min_child_weight':0.001,'reg_alpha':0.1,'reg_lambda':0.1,\n",
        "            'random_state':42,'verbose':-1,'n_jobs':-1\n",
        "        }\n",
        "        self.params.update(params)\n",
        "        self.model=None\n",
        "    def fit(self,X,y,eval_set=None,early_stopping_rounds=100,verbose=False):\n",
        "        dtrain = lgb.Dataset(X,label=y)\n",
        "        valid_sets=[dtrain]; valid_names=['train']\n",
        "        if eval_set is not None:\n",
        "            dval = lgb.Dataset(eval_set[0],label=eval_set[1],reference=dtrain)\n",
        "            valid_sets.append(dval); valid_names.append('valid')\n",
        "        self.model = lgb.train(\n",
        "            self.params, dtrain,\n",
        "            valid_sets=valid_sets, valid_names=valid_names,\n",
        "            num_boost_round=10000,\n",
        "            callbacks=[\n",
        "                lgb.early_stopping(early_stopping_rounds, verbose=verbose),\n",
        "                lgb.log_evaluation(100 if verbose else 0)\n",
        "            ]\n",
        "        )\n",
        "        return self\n",
        "    def predict(self,X):\n",
        "        return self.model.predict(X, num_iteration=self.model.best_iteration)\n",
        "    def get_feature_importance(self):\n",
        "        return self.model.feature_importance(importance_type='gain')\n",
        "\n",
        "def weighted_mae(y_true, y_pred, is_holiday):\n",
        "    weights = np.where(is_holiday, 5, 1)\n",
        "    return np.sum(weights * np.abs(y_true-y_pred)) / np.sum(weights)\n",
        "\n",
        "def evaluate_model(y_true, y_pred, is_holiday_series):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    wmae= weighted_mae(y_true, y_pred, is_holiday_series.values)\n",
        "    print(f\"MAE: {mae:.4f}, WMAE: {wmae:.4f}\")\n",
        "    return {'mae':mae,'wmae':wmae}\n",
        "\n",
        "\n",
        "expected_features_after_preprocessing = [\n",
        "    'Store','Dept','IsHoliday','Size','Temperature','Fuel_Price','CPI','Unemployment',\n",
        "    'MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5','Type',\n",
        "    'Year','Month','Week','DayOfYear','Quarter',\n",
        "    'Month_sin','Month_cos','Week_sin','Week_cos',\n",
        "    'Store_Dept_Mean_Sales','Store_Mean_Sales','Dept_Mean_Sales','Sales_per_Size',\n",
        "    'Holiday_Dept','Holiday_Store'\n",
        "]\n",
        "\n",
        "# 7.1 Fit preprocessor\n",
        "pre = WalmartPreprocessor(target_columns=expected_features_after_preprocessing)\n",
        "pre.fit(X_train_for_pipeline, y_train)\n",
        "\n",
        "# 7.2 Transform\n",
        "X_train_trans = pre.transform(X_train_for_pipeline)\n",
        "X_val_trans   = pre.transform(X_val_for_pipeline)\n",
        "\n",
        "# 7.3 Train LightGBM\n",
        "model = LightGBMRegressor()\n",
        "model.fit(\n",
        "    X_train_trans, y_train,\n",
        "    eval_set=(X_val_trans, y_val),\n",
        "    early_stopping_rounds=100,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 7.4 Wrap into a pipeline\n",
        "full_prediction_pipeline = Pipeline([\n",
        "    ('preprocessor', pre),\n",
        "    ('lgbm_model',    model)\n",
        "])\n",
        "\n",
        "# Save pipeline\n",
        "joblib.dump(full_prediction_pipeline, \"models/lightgbm_full_pipeline_approach2.pkl\")\n",
        "\n",
        "\n",
        "y_train_pred = full_prediction_pipeline.predict(X_train_for_pipeline)\n",
        "y_val_pred   = full_prediction_pipeline.predict(X_val_for_pipeline)\n",
        "\n",
        "print(\"Training performance:\")\n",
        "evaluate_model(y_train, y_train_pred, X_train['IsHoliday'])\n",
        "print(\"Validation performance:\")\n",
        "evaluate_model(y_val, y_val_pred, X_val['IsHoliday'])\n",
        "\n",
        "\n",
        "y_test_pred = full_prediction_pipeline.predict(df_full_test)\n",
        "y_test_pred[y_test_pred < 0] = 0\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'Id': df_full_test['Store'].astype(str) + '_' + \\\n",
        "          df_full_test['Dept'].astype(str) + '_' + \\\n",
        "          df_full_test['Date'].dt.strftime('%Y-%m-%d'),\n",
        "    'Weekly_Sales': y_test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_approach2.csv', index=False)\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkIbTn51IOHJ",
        "outputId": "3ae2ad0a-cb60-4a7e-d9de-af867198ccb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/1h3JmMNvF7pLor34P-qm2FEkIev93euuf/ML_FInal_Project\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttrain's l1: 2476.96\tvalid's l1: 2626.57\n",
            "[200]\ttrain's l1: 2206.26\tvalid's l1: 2533.19\n",
            "[300]\ttrain's l1: 2068.57\tvalid's l1: 2502.76\n",
            "[400]\ttrain's l1: 1978.78\tvalid's l1: 2467.22\n",
            "[500]\ttrain's l1: 1906.2\tvalid's l1: 2444.3\n",
            "[600]\ttrain's l1: 1851.51\tvalid's l1: 2441.01\n",
            "[700]\ttrain's l1: 1802.75\tvalid's l1: 2426.7\n",
            "[800]\ttrain's l1: 1761.68\tvalid's l1: 2420\n",
            "[900]\ttrain's l1: 1727.23\tvalid's l1: 2419\n",
            "[1000]\ttrain's l1: 1694.46\tvalid's l1: 2415.07\n",
            "[1100]\ttrain's l1: 1663.29\tvalid's l1: 2409.82\n",
            "[1200]\ttrain's l1: 1635.04\tvalid's l1: 2402.11\n",
            "[1300]\ttrain's l1: 1611.72\tvalid's l1: 2403.17\n",
            "Early stopping, best iteration is:\n",
            "[1263]\ttrain's l1: 1620.68\tvalid's l1: 2400.06\n",
            "Training performance:\n",
            "MAE: 1620.6770, WMAE: 1681.6187\n",
            "Validation performance:\n",
            "MAE: 2400.0606, WMAE: 2444.3509\n",
            "               Id  Weekly_Sales\n",
            "0  1_1_2012-11-02  25244.667427\n",
            "1  1_1_2012-11-09  26787.279695\n",
            "2  1_1_2012-11-16  27581.755397\n",
            "3  1_1_2012-11-23  24848.323035\n",
            "4  1_1_2012-11-30  43561.895008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HwI6ZOMSM-Rf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}