{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DPw7vrdkLiuG",
        "outputId": "980b27d7-2c13-4651-b4ad-5a1c4a216851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.3-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.3-py3-none-any.whl (246 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.9/246.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.3 colorlog-6.9.0 optuna-4.4.0\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ML_FInal_Project\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlkata22\u001b[0m (\u001b[33mlkata22-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/ML_FInal_Project/wandb/run-20250708_193145-glbzcmv8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/glbzcmv8' target=\"_blank\">XGBoost_train_test_v2</a></strong> to <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/glbzcmv8' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/glbzcmv8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mae:14907.10032\tvalid-mae:14804.28869\n",
            "[100]\ttrain-mae:3029.80180\tvalid-mae:2521.02915\n",
            "[200]\ttrain-mae:1853.33448\tvalid-mae:1439.26116\n",
            "[300]\ttrain-mae:1667.26870\tvalid-mae:1390.59631\n",
            "[385]\ttrain-mae:1590.81699\tvalid-mae:1398.29752\n",
            "MAE:1398.30  RMSE:3074.57  WMAE:1426.32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>mae_final</td><td>▁</td></tr><tr><td>rmse_final</td><td>▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_mae</td><td>█▇▇▆▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_mae</td><td>█▆▅▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wmae_final</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>mae_final</td><td>1398.29752</td></tr><tr><td>rmse_final</td><td>3074.56863</td></tr><tr><td>step</td><td>385</td></tr><tr><td>train_mae</td><td>1590.81699</td></tr><tr><td>valid_mae</td><td>1398.29752</td></tr><tr><td>wmae_final</td><td>1426.31645</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">XGBoost_train_test_v2</strong> at: <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/glbzcmv8' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting/runs/glbzcmv8</a><br> View project at: <a href='https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting' target=\"_blank\">https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting</a><br>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250708_193145-glbzcmv8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  Run complete - metrics & curves logged to WandB.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 0. Google Drive  &  library installs\n",
        "!pip install optuna\n",
        "\n",
        "from google.colab import drive\n",
        "import os, json, joblib, warnings, math, holidays, optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics        import mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from datetime                import datetime\n",
        "\n",
        "import wandb\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# 1.  Drive + env setup\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/ML_FInal_Project\n",
        "!pip install -q wandb xgboost scikit-learn pandas numpy matplotlib holidays optuna\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# 2.  WandB initialisation\n",
        "\n",
        "wandb.login()\n",
        "run = wandb.init(\n",
        "    project = \"walmart-sales-forecasting\",\n",
        "    entity  = \"lkata22-free-university-of-tbilisi-\",\n",
        "    name    = \"XGBoost_train_test_v2\",\n",
        "    group   = \"XGBoost\",\n",
        "    config  = {\n",
        "        \"random_seed\": SEED,\n",
        "        \"n_estimators\": 2500,\n",
        "        \"learning_rate\": 0.02,\n",
        "        \"max_depth\": 8,\n",
        "        \"subsample\": 0.75,\n",
        "        \"colsample_bytree\": 0.75,\n",
        "        \"gamma\": 0.1,\n",
        "        \"min_child_weight\": 5,\n",
        "        \"reg_alpha\": 0.1,\n",
        "        \"reg_lambda\": 0.1,\n",
        "        \"early_stopping_rounds\": 100,\n",
        "        \"eval_metric\": \"mae\",\n",
        "        \"tree_method\": \"hist\"\n",
        "    }\n",
        ")\n",
        "config = wandb.config\n",
        "\n",
        "\n",
        "# 3.  Data loading & merge\n",
        "\n",
        "DATA_PATH = \"data\"\n",
        "train    = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
        "features = pd.read_csv(f\"{DATA_PATH}/features.csv\")\n",
        "stores   = pd.read_csv(f\"{DATA_PATH}/stores.csv\")\n",
        "\n",
        "raw_df = (train\n",
        "          .merge(features, on=[\"Store\",\"Date\",\"IsHoliday\"], how=\"left\")\n",
        "          .merge(stores,   on=\"Store\",                how=\"left\")\n",
        "         )\n",
        "\n",
        "# 4.  Feature engineering helper\n",
        "us_holidays = holidays.US()\n",
        "\n",
        "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    # core date parts\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df[\"Year\"]  = df.Date.dt.year\n",
        "    df[\"Month\"] = df.Date.dt.month\n",
        "    df[\"Week\"]  = df.Date.dt.isocalendar().week.astype(int)\n",
        "    df[\"Day\"]   = df.Date.dt.day\n",
        "    # holiday flags\n",
        "    df[\"IsHoliday\"]    = df[\"IsHoliday\"].astype(int)\n",
        "    df[\"IsUSHoliday\"] = df[\"Date\"].isin(us_holidays).astype(int)\n",
        "    # type one-hot\n",
        "    df = pd.get_dummies(df, columns=[\"Type\"], drop_first=True)\n",
        "    # ensure chronological order for lags\n",
        "    df.sort_values([\"Store\",\"Dept\",\"Date\"], inplace=True)\n",
        "    # simple lags + rolling means\n",
        "    for lag in [4, 52]:\n",
        "        df[f\"lag_{lag}\"] = df.groupby([\"Store\",\"Dept\"])[\"Weekly_Sales\"].shift(lag)\n",
        "    for win in [4, 52]:\n",
        "        df[f\"roll_mean_{win}\"] = (df\n",
        "             .groupby([\"Store\",\"Dept\"])[\"Weekly_Sales\"]\n",
        "             .shift(1)\n",
        "             .rolling(window=win, min_periods=1).mean())\n",
        "    return df.fillna(0)\n",
        "\n",
        "# apply engineering\n",
        "df = create_features(raw_df)\n",
        "TARGET  = \"Weekly_Sales\"\n",
        "DROP    = [\"Date\", TARGET]\n",
        "FEATURES= [c for c in df.columns if c not in DROP]\n",
        "\n",
        "\n",
        "# 5.  Time-based 80/20 train-test split\n",
        "\n",
        "cutoff = df[\"Date\"].quantile(0.8)\n",
        "train_df = df[df[\"Date\"] <= cutoff]\n",
        "test_df  = df[df[\"Date\"] >  cutoff]\n",
        "\n",
        "X_train, y_train = train_df[FEATURES], train_df[TARGET]\n",
        "X_test,  y_test  = test_df[FEATURES],  test_df[TARGET]\n",
        "holiday_test     = test_df[\"IsHoliday\"].values\n",
        "\n",
        "\n",
        "# 6.  XGBoost training with **live logging**\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dvalid = xgb.DMatrix(X_test,  label=y_test)\n",
        "\n",
        "params = {k: config[k] for k in [\n",
        "    \"learning_rate\",\"max_depth\",\"subsample\",\"colsample_bytree\",\n",
        "    \"gamma\",\"min_child_weight\",\"reg_alpha\",\"reg_lambda\",\n",
        "    \"tree_method\",\"eval_metric\"]}\n",
        "params[\"objective\"] = \"reg:squarederror\"\n",
        "\n",
        "\n",
        "evals_result = {}\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=config.n_estimators,\n",
        "    evals=[(dtrain,\"train\"),(dvalid,\"valid\")],\n",
        "    early_stopping_rounds=config.early_stopping_rounds,\n",
        "    evals_result=evals_result,\n",
        "    verbose_eval=100\n",
        ")\n",
        "\n",
        "\n",
        "for i in range(len(evals_result[\"train\"][\"mae\"])):\n",
        "    wandb.log({\n",
        "        \"train_mae\":  evals_result[\"train\"][\"mae\"][i],\n",
        "        \"valid_mae\":  evals_result[\"valid\"][\"mae\"][i],\n",
        "        \"step\":       i\n",
        "    })\n",
        "\n",
        "\n",
        "# 7.  Final evaluation\n",
        "ypred = model.predict(dvalid)\n",
        "mae  = mean_absolute_error(y_test, ypred)\n",
        "rmse = math.sqrt(mean_squared_error(y_test, ypred))\n",
        "weights = np.where(holiday_test==1, 5, 1)\n",
        "wmae = np.sum(weights * np.abs(y_test - ypred)) / weights.sum()\n",
        "\n",
        "wandb.log({\"mae_final\":mae, \"rmse_final\":rmse, \"wmae_final\":wmae})\n",
        "print(f\"MAE:{mae:.2f}  RMSE:{rmse:.2f}  WMAE:{wmae:.2f}\")\n",
        "\n",
        "# feature importance image\n",
        "fig, ax = plt.subplots(figsize=(10,12))\n",
        "xgb.plot_importance(model, max_num_features=40, ax=ax)\n",
        "plt.tight_layout()\n",
        "wandb.log({\"feature_importance\": wandb.Image(fig)})\n",
        "plt.close(fig)\n",
        "\n",
        "\n",
        "# 8.  Save artefacts\n",
        "\n",
        "model_name = f\"xgb_split_{datetime.now().strftime('%Y%m%d_%H%M')}.json\"\n",
        "model.save_model(os.path.join(\"models\", model_name))\n",
        "art = wandb.Artifact(\"xgb_split_model\", type=\"model\")\n",
        "art.add_file(os.path.join(\"models\", model_name))\n",
        "wandb.log_artifact(art)\n",
        "\n",
        "wandb.finish()\n",
        "print(\"✅  Run complete - metrics & curves logged to WandB.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11gFvVt6jl8h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}