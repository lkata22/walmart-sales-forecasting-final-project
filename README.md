### პროექტზე მუშაობდნენ: ლუკა ქათამაძე , ალექსანდრე სურმავა

# პროექტის მიმოხილვა – Walmart Recruiting: Store Sales Forecasting


## მონაცემების აღწერა

  მონაცემები შეიცავს შემდეგ სვეტებს:
  
  Store – მაღაზიის უნიკალური იდენტიფიკატორი
      
  Dept – დეპარტამენტის იდენტიფიკატორი
  
  Date – კვირის პირველი დღე (დროითი ღერძი)
  
  Weekly_Sales – იმ კვირაში გაყიდული პროდუქციის თანხა (ჩვენი სამიზნე ცვლადი)
  
  IsHoliday – აღნიშნული კვირა მოიცავს თუ არა დღესასწაულს
  
  დამატებით მოცემულია:
  
  features.csv – გარეგანი ფაქტორები, როგორიცაა CPI, ბენზინის ფასი, უმუშევრობის დონე და ა.შ.
  
  stores.csv – მაღაზიების ტიპი და ზომა

## მონაცემების ანალიზი 

  ### cleaning
  პროექტის საწყის ეტაპზე მოხდა მოცემული სამივე მონაცემის ფაილის (train.csv, features.csv, stores.csv) გაერთიანება Store და Date სვეტების მიხედვით.
  Weekly_Sales ცვლადში აღმოჩენილი უარყოფითი ან ნულოვანი მნიშვნელობები წარმოადგენდა მხოლოდ 0.3%-ს. ისინი იქნა ამოღებული.
  Markdown სვეტებში იყო ბევრი NaN მნიშვნელობა. ისინი ჩავანაცვლეთ 0-ით.
  ### თარიღის დამუშავება
  -- Date ველი გარდაიქმნა datetime ფორმატში, რის შემდეგაც შეიქმნა ახალი სვეტები:
            year,month,week.
  -- ასევე განვათავსეთ ოთხი მნიშვნელოვანი დღესასწაული ცალკე ბულიან სვეტებად, რადგან გვინდოდა გვენახა , როგორ იყო დამოკიდებული weekly_sales მათთან:
            Thanksgiving,Christmas,Super_Bowl,Labor_Day


 
  ![image](https://github.com/user-attachments/assets/b6a1d80e-30d2-4a18-86a5-6f4a990184c6)

  
  ![image](https://github.com/user-attachments/assets/0c2b497f-999e-44c8-abdc-cf68d596c057)


  ![image](https://github.com/user-attachments/assets/219e6d87-26f2-496f-b189-13029ed87c5c)


  ![image](https://github.com/user-attachments/assets/363bf5f2-fc18-4521-8b68-f74acce58a48)


  ![image](https://github.com/user-attachments/assets/e5ad498a-f0db-4a34-893e-9be6df769040)



  ჩანს , რომ Labor Day და Christmas ძალიან არ ცვლის გაყიდვებს. ყველაზე მეტად მასზე ახდენს ზემოქმედებას Thanksgiving.


  ## დეპარტამენტები და მაღაზიები
  
  მონაცემები მოიცავს 45 მაღაზიას და 81 დეპარტამენტს – თუმცა ყველა დეპარტამენტი არ არის ხელმისაწვდომი ყველა მაღაზიაში.
  ყველაზე მაღალი საშუალო გაყიდვები ჰქონდა დეპარტამენტს 92, თუმცა ყველაზე მაღალი ინდივიდუალური გაყიდვები იყო დეპარტამენტი 72-ში, ძირითადად Thanksgiving-ის კვირაში.

  მაღაზიებს აქვთ ტიპები A, B, C — ტიპი A უდიდესია ზომით (>150,000), და მას აქვს ყველაზე მაღალი საშუალო გაყიდვები.

  ყველაზე მაღალი გაყიდვები დაფიქსირდა Thanksgiving-ის, Christmas-ის და Black Friday-ის კვირებში (კვირები 47–51).

  
  
  ![image](https://github.com/user-attachments/assets/578b19a8-659d-432f-862b-61ae0503caff)


  ![image](https://github.com/user-attachments/assets/5da5436a-f2fd-4149-8cf5-aee4382f5089)


  ![image](https://github.com/user-attachments/assets/16f07a85-c2ca-475d-bbee-dca926a10da0)


  ![image](https://github.com/user-attachments/assets/43305902-de05-446a-bd66-bd0ac2328d52)


  ![image](https://github.com/user-attachments/assets/a1708504-c633-43b8-a3ba-8f1f2f737c34)


  ქვედა გფაფი აჩვენებს გაყიდვებს წლების მიხედვით.

  

  ![image](https://github.com/user-attachments/assets/603177ee-071d-4e42-a131-919f8bc016fb)

  

  კვირების მიხედვით:


  ![image](https://github.com/user-attachments/assets/730193dc-8cbb-40bb-b3ef-989a510be193)



   CPI, Fuel Price, Unemployment, Temperature არ აჩვენებს გამოკვეთილ კორელაციას Weekly_Sales-თან.



   ![image](https://github.com/user-attachments/assets/116c2ee3-530f-4b9b-8b44-e9f84e6ad605)



   ![image](https://github.com/user-attachments/assets/22c91452-e4fb-44ea-84f8-69c5fb72dfde)



   ![image](https://github.com/user-attachments/assets/a9d92048-8f56-49bf-9350-b2f6eca4185a)



   ![image](https://github.com/user-attachments/assets/c2c4b0ed-8aa4-4d05-8b5e-f9d612be6bf6)



# მოდელები 
 
 ## მოდელი: DLinear (Decomposition Linear)
   ამ პროექტში დაიტესტა DLinear მოდელის არქიტექტურა NeuralForecast ბიბლიოთეკის გამოყენებით.

   ### მოდელის კონფიგურაცია:
   
    * horizon: 28 (forecast horizon in weeks)
    * input_size: 30 (look-back window in weeks)
    * epochs (max_steps): 500
    * batch_size: 64
    * learning_rate: 1e-3

  მოდელი ტრენდება Weights & Biases (W&B) პლატფორმაზე, სადაც ხდება ყველა ექსპერიმენტის დეტალური ლოგირება.

  ### მონაცემთა დამუშავება

    * უარყოფითი Weekly_Sales მნიშვნელობები გადაკეთდა ნულზე
    * შეიქმნა უნიკალური იდენტიფიკატორი Store_Dept ფორმატით
    * Date გადაერქვა ds, ხოლო Weekly_Sales – y, რათა მოდელი თავსებადი ყოფილიყო NeuralForecast ფორმატთან

  ### შეიქმნა DLinearNF კლასი, რომელიც საშუალებას იძლევა:
      * ააგოს DLinear მოდელი მორგებული პარამეტრებით (h და input_size)
      * გახდეს თავსებადი NeuralForecast სტრუქტურასთან
      * გააქტიუროს start_padding_enabled, რათა გაითვალისწინოს მოკლე სერიები
      * გაუშვას ტრენინგი და პროგნოზი fit() და predict() მეთოდებით



##  მოდელი: PatchTST

### მიმოხილვა

აღნიშნულ ნაწილში აგებული იყო **PatchTST** ტიპის პროგნოზირების pipeline, რომლის მიზანია Walmart-ის ყოველკვირეული გაყიდვების სერიისთვის ლოკალური და გლობალური დროითი პატერნების დაჭერა ყველა Store–Item სერიაზე.

### ძირითადი ლოგიკა

1. **სლაიდინგ ფანჯრის მონაცემთა ფორმატირება:** ყოველი დროითი სერია დაიყო ფიქსირებული სიგრძის შესატანი და სამიზნე ფანჯრებად, რაც საშუალებას აძლევს მოდელს ისწავლოს ჯგუფურად პატჩებზე.
2. **PatchTST არქიტექტურა:** შესატანი სერიები იყოფა გადაფარვად პატჩებად. მოდელი იყენებს self-attention მექანიზმს, რათა ისწავლოს როგორც ერთ პატჩში არსებული ისე სხვადასხვა პატჩის გადაკვეთის დამოკიდებულებები – რაც აუმჯობესებს გრძელვადიანი სტრუქტურების დამუშავებას.
3. **სრული ისტორიის გამოყენება და Hold-Out ტესტი:** ტრენინგი მიმდინარეობს მთლიან ხელმისაწვდომ ისტორიაზე, ხოლო ტესტის ჰორიზონტზე მოდელი აკეთებს პროგნოზს და შედეგები შედარებულია რეალურ გაყიდვებთან.

### სწავლების პროცესი

- Optimizer: **Adam**, მიზანი: **MSE** მინიმიზაცია
- ყოველი epoch-ს ლოსი ლოგირებულია **Weights & Biases** პლატფორმაზე მონიტორინგისთვის

### შეფასება

- Hold-out ფანჯარაზე გამოითვალა ორი მეტრიკა:
  - **SMAPE (Symmetric Mean Absolute Percentage Error)**
  - **MAE (Mean Absolute Error)**
- თითოეული სერიის შეფასება აგრეგირდა გლობალურ დონეზე საერთო სიზუსტის მაჩვენებლად



## მოდელები: ARIMA და SARIMA

### 1. ARIMA – საწყისი Benchmark

**მიზანი:** 
დროითი მონაცემების საწყისი ანალიზი და მარტივი ბაზისური პროგნოზის შექმნა.

**იმპლემენტაცია:**
- დატვირთული იყო გაყიდვების სერია `(Store, Dept)` წყვილისთვის.
- ყოველ სერიაზე მოხდა **ARIMA (1,1,1)** მოდელის გაშვება `statsmodels` ბიბლიოთეკით.
- შეფასება შესრულდა **MAE (Mean Absolute Error)** მეტრიკით.

** ძირითადი დაკვირვება:**  
მოდელმა კარგად დააფიქსირა ზოგადი ტრენდი, თუმცა ვერ გაუმკლავდა დღესასწაულებს.

---

### 2.  SARIMA – სეზონურობის დამუშავება


** იმპლემენტაცია:**
- გამოყენებული იყო **SARIMAX** მოდელი სეზონური პარამეტრებით: `(0,1,1,52)` – რაც წელიწადის სეზონურ ციკლს მოიცავს.
- დაემატა ცვლადები (`Temperature`, `Fuel_Price`, `CPI`, `Unemployment`).
- შეფასების მეტრიკები და დიაგნოსტიკა დაილოგა **Weights & Biases (W&B)**-ზე.

** ძირითადი დაკვირვება:**  
სეზონურმა კომპონენტებმა და დამატებითმა ფიჩერებმა გააუმჯობესეს პროგნოზი, მაგრამ მოდელის სწავლა თითო სერიაზე ძალიან ნელი იყო.



 ##  მოდელი: LightGBM 


### ეტაპები და მიდგომები

#### საწყისი მოდელი (Baseline)


- **შედეგები:**
  - MAE: ~1,700
  - სწავლების დრო: 30+ წუთი
- **პრობლემა:** ზედმეტად გადატვირთული არასაჭირო მახასიათებლებით.

---

#### ოპტიმიზირებული საბოლოო მოდელი

** განხორციელებული ცვლილებები:**

1. **მახასიათებლების გამარტივება:**
   - დატოვებულია მხოლოდ მნიშვნელოვანი დღესასწაულები: `Super_Bowl`, `Thanksgiving`
   - დამატებულია `Days_Until_Holiday` – დაეხმაროს მოდელს მოსალოდნელი ზრდის წინასწარ ნახვაში
   -  სტატისტიკებიდან დარჩა მხოლოდ 4-კვირიანი საშუალო

2. **სწავლის აჩქარება:**
   - Boosting ტიპი შეცვლილია `dart`-იდან `gbdt`-ზე (სწავლა გახდა 3-ჯერ სწრაფი)
   - `learning_rate` გაზრდილი 0.03-დან 0.1-მდე და `num_rounds` შემცირდა 2000-დან 800-მდე
   - `num_leaves` შემცირდა → მოდელის კომპლექსობის შემცირება, თუმცა დამატებულია `lambda_l2`, რათა აიცილოს overlearning

3. **დღესასწაულები:**
   
   - დამატებულია `Pre_Holiday_Week` ცვლადი, რათა დაიჭიროს დღემდე გაყიდვების მატება.

---


##  მოდელი: Prophet



### იმპლემენტაცია

- **მონაცემთა წინამზადება:**
  - გაერთიანდა `train.csv`, `features.csv`, `stores.csv` მონაცემები.
  - `Weekly_Sales` გადაერქვა `y`, ხოლო `Date` – `ds`, Prophet-სთვის საჭირო ფორმატში.
  - გამოყენებულია US-ის ოფიციალური დღესასწაულები (`holidays` ბიბლიოთეკით).
  - გაყოფილი იყო მონაცემები 80% ტრენინგზე და 20% ტესტზე დროით სექვენსით.

- **ტრენინგის მახასიათებლები:**
  - ტრენინგი შესრულდა თითოეული `(Store, Dept)` სერიისთვის ინდივიდუალურად.
  - გამოყენებული პარამეტრები:
    - `changepoint_prior_scale`: 0.15
    - `seasonality_prior_scale`: 10.0
    - `holidays_prior_scale`: 10.0
    - `yearly_seasonality`: `True`
    - `weekly_seasonality`: `True`
    - `seasonality_mode`: `"multiplicative"`

- **შეფასების მეტრიკები:**
  - `MAE`, `RMSE` და **WMAE** (სასწორიანი MAE დღესასწაულებზე განსაკუთრებული ყურადღებით).
  - დღესასწაულების კვირებისთვის გამოყენებული იყო წონა 5, დანარჩენებისთვის 1.

- **ლოგირება და შენახვა:**
  - თითოეული მოდელის შედეგები და მეტრიკები დალოგდა **Weights & Biases (W&B)** პლატფორმაზე.
  - მოდელები შენახულია ინდივიდუალურად `.pkl` ფაილებად (`models/prophet_store{X}_dept{Y}.pkl`).
  - ყველა სერიის შედეგები შენახულია CSV ფაილში და ატვირთულია როგორც W&B არტიფაქტი.

---

### ძირითადი დაკვირვებები

- Prophet მოახერხა სეზონური ტენდენციებისა და დღესასწაულების ეფექტების დაჭერა.
- თუმცა, ტრენინგის დრო და რესურსები იზრდებოდა თითო სერიაზე ინდივიდუალური სწავლების გამო.
- **WMAE მნიშვნელობები** აჩვენებდა, რომ მოდელი შედარებით კარგად გაუმკლავდა დღესასწაულების პროგნოზს.

საბოლოოდ, Prophet აღმოჩნდა კარგი კლასიკური მოდელი, რომელიც მინიმალური პარამეტრებით უზრუნველყოფს ინტერპრეტირებად შედეგებს და კარგად ერგება სეზონური გაყიდვების სერიებს.


##  მოდელი: XGBoost


###  იმპლემენტაცია

- **მონაცემთა მომზადება:**
  - გაერთიანდა `train.csv`, `features.csv`, `stores.csv`.
  - შექმნილია ახალი თვისებები:
    - თარიღის ნაწილები: `Year`, `Month`, `Week`, `Day`
    - დღესასწაულის ინდიკატორები: `IsHoliday`, `IsUSHoliday`
    - `Type` გადაყვანილია one-hot ფორმატში
    - Lag ცვლადები: 4-კვირიანი და 52-კვირიანი გაყიდვები
  - ცვლადები ავტომატურად შევსებულია `fillna(0)`–ით

- **მოდელის პარამეტრები (W&B Config):**
  - `n_estimators`: 2500
  - `learning_rate`: 0.02
  - `max_depth`: 8
  - `subsample`, `colsample_bytree`: 0.75
  - `gamma`: 0.1
  - `min_child_weight`: 5
  - რეგულარიზაცია: `reg_alpha`, `reg_lambda`: 0.1
  - `tree_method`: `"hist"` (სწრაფი ხის აგება)

- **Train/Test გაყოფა:**
  - განხორციელდა დროით 80/20 გაყოფა (`Date` ველის მიხედვით)
  - ტრენინგი მიმდინარეობდა `DMatrix` ფორმატში
  - Early stopping გამოყენებულია 100 epoch-ზე

---

### შეფასება

- გამოყენებული მეტრიკები:
  - **MAE** 
  - **RMSE** 
  - **WMAE** – weighted MAE
- შედეგები დაილოგა **Weights & Biases** პლატფორმაზე
- ვიზუალიზაცია: Feature Importance ჩატვირთულია როგორც სურათი W&B-ზე

---

### ძირითადი დაკვირვებები

- XGBoost გამოჩნდა როგორც სწრაფი და ეფექტური ალგორითმი დიდი მოცულობის გაყიდვების სერიებზე.
- Feature Engineering (განსაკუთრებით lag და rolling საშუალო) მნიშვნელოვნად ზრდიდა სიზუსტეს.
- დღესასწაულებზე ფოკუსირებული შეფასება (WMAE) აჩვენებს, რომ მოდელი კარგად აღწერს მაღაზიების ქცევას განსაკუთრებულ კვირებში.




##  მოდელი: N-BEATS (Neural Basis Expansion Analysis for Time Series)


---

### იმპლემენტაცია

- **მოდელის არქიტექტურა:**
  - გამოყენებულია ორ სტეკად გაყოფილი N-BEATS:
    - `Trend` 
    - `Seasonality` 

- **ტექნიკური პარამეტრები:**
  - Lookback ფანჯარა: 52 კვირა  
  - პროგნოზის ფანჯარა: 8 კვირა  
  - Optimizer: `Adam`  
  - Scheduler: ReduceLROnPlateau  
  - Batch size: 32  
  - Epochs: 100 (კოდში 15 -ია მაგრამ ძალიან დიდ ხანს უნდებოდა და ამიტომ შევამცირეთ)
  - Early stopping: patience = 20

- **მონაცემთა დამუშავება:**
  - გაერთიანდა `train.csv`, `features.csv`, `stores.csv`
  - დროითი სერიები შეგროვდა ინდივიდუალურად `Store`-სა და `Dept`-ზე
  - ყველა სერიამ გაიარა სტანდარტულ სკალირებაზე (`StandardScaler`)
  - მონაცემები გარდაიქმნა `TimeSeriesDataset` კლასით PyTorch-ის `DataLoader` ფორმატში
---

### შეფასება

- შეფასება მოხდა შემდეგი მეტრიკებით:
  - **MAE** – საშუალო აბსოლუტური შეცდომა  
  - **RMSE** – ფესვი საშუალო კვადრატული შეცდომისგან  
  - **R² Score** – დეტერმინაციის კოეფიციენტი

| მეტრიკა | მნიშვნელობა |
|--------|-------------|
| MAE    | ~ 1249.79
| RMSE   | ~ 3038.62
| R²     | ~ 0.9755


---

### ძირითადი დასკვნები

- **N-BEATS** არქიტექტურა წარმატებით ასახავს როგორც გრძელვადიან ტენდენციებს, ისე სეზონურ მერყეობებს.
- ტრენინგი სტაბილურია მცირე ეპოქების რაოდენობითაც, რაც აჩენს მოდელის ეფექტურობას.



## მოდელი: Random Forest


###  იმპლემენტაცია

- **მონაცემთა დამუშავება:**
  - გაერთიანდა `train.csv`, `features.csv` და `stores.csv` მონაცემები.
  - წაშლილია არასაიმედო თარიღები და გაუქმებულია დუბლიკატები.
  - დაემატა დროითი და ციკლური ფიჩერები (`Month_sin`, `Week_cos` და სხვ.).

- **ფუნქციური ინჟინერია:**
  - ლაგებისა და მოძრავი საშუალო ფიჩერების დამატება (`Sales_Lag_1`, `Sales_Rolling_4` და სხვ.).
  - Markdown-ებზე დაფუძნებული ველების შექმნა (`MarkDown1_Flag`, `Total_MarkDown`).
  - Store-Dept ინტერაქციის ფიჩერი (`Dept_Store_Interaction`).

- **ტრენინგი:**
  - გამოყენებულია `RandomForestRegressor` sklearn-დან.
  - მხარდაჭერილია ჰიპერპარამეტრების ტიუნინგი `GridSearchCV`-ით.
  - Default მოდელის პარამეტრები:
    - `n_estimators`: 100
    - `max_depth`: 20
    - `max_features`: `'sqrt'`
  - მონაცემთა გაყოფა 80/20 პროპორციით (Chronological Split).

- **შეფასების მეტრიკები:**
  - `MAE`, `RMSE`, `R²` როგორც ტრენინგზე, ისე ტესტზე.
  - დამატებით ითვლება **overfitting მეტრიკები** (`train vs. test` შედარება).

- **ლოგირება:**
  - ყველა პარამეტრი, მეტრიკა და ვიზუალიზაცია აიტვირთება **MLflow**-ზე.
  - ჩაიწერა:
    - Feature Importance
    - Actual vs Predicted გრაფიკები
    - Residual Plot
    - Forecaster არტიფაქტები (Forecast CSV, Feature CSV, Encoders)

---





mlflow:  https://dagshub.com/lkata22/walmart-sales-forecasting-final-project.mlflow/#/experiments/1?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D

wandb:   https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting?nw=nwuserlkata22




  
  

  


 






  
