### პროექტზე მუშაობდნენ: ლუკა ქათამაძე , ალექსანდრე სურმავა

# პროექტის მიმოხილვა – Walmart Recruiting: Store Sales Forecasting


## მონაცემების აღწერა

  მონაცემები შეიცავს შემდეგ სვეტებს:
  
  Store – მაღაზიის უნიკალური იდენტიფიკატორი
      
  Dept – დეპარტამენტის იდენტიფიკატორი
  
  Date – კვირის პირველი დღე (დროითი ღერძი)
  
  Weekly_Sales – იმ კვირაში გაყიდული პროდუქციის თანხა (ჩვენი სამიზნე ცვლადი)
  
  IsHoliday – აღნიშნული კვირა მოიცავს თუ არა დღესასწაულს
  
  დამატებით მოცემულია:
  
  features.csv – გარეგანი ფაქტორები, როგორიცაა CPI, ბენზინის ფასი, უმუშევრობის დონე და ა.შ.
  
  stores.csv – მაღაზიების ტიპი და ზომა

## მონაცემების ანალიზი 

  ### cleaning
  პროექტის საწყის ეტაპზე მოხდა მოცემული სამივე მონაცემის ფაილის (train.csv, features.csv, stores.csv) გაერთიანება Store და Date სვეტების მიხედვით.
  Weekly_Sales ცვლადში აღმოჩენილი უარყოფითი ან ნულოვანი მნიშვნელობები წარმოადგენდა მხოლოდ 0.3%-ს. ისინი იქნა ამოღებული.
  Markdown სვეტებში იყო ბევრი NaN მნიშვნელობა. ისინი ჩავანაცვლეთ 0-ით.
  ### თარიღის დამუშავება
  -- Date ველი გარდაიქმნა datetime ფორმატში, რის შემდეგაც შეიქმნა ახალი სვეტები:
            year,month,week.
  -- ასევე განვათავსეთ ოთხი მნიშვნელოვანი დღესასწაული ცალკე ბულიან სვეტებად, რადგან გვინდოდა გვენახა , როგორ იყო დამოკიდებული weekly_sales მათთან:
            Thanksgiving,Christmas,Super_Bowl,Labor_Day


 
  ![image](https://github.com/user-attachments/assets/b6a1d80e-30d2-4a18-86a5-6f4a990184c6)

  
  ![image](https://github.com/user-attachments/assets/0c2b497f-999e-44c8-abdc-cf68d596c057)


  ![image](https://github.com/user-attachments/assets/219e6d87-26f2-496f-b189-13029ed87c5c)


  ![image](https://github.com/user-attachments/assets/363bf5f2-fc18-4521-8b68-f74acce58a48)


  ![image](https://github.com/user-attachments/assets/e5ad498a-f0db-4a34-893e-9be6df769040)



  ჩანს , რომ Labor Day და Christmas ძალიან არ ცვლის გაყიდვებს. ყველაზე მეტად მასზე ახდენს ზემოქმედებას Thanksgiving.


  ## დეპარტამენტები და მაღაზიები
  
  მონაცემები მოიცავს 45 მაღაზიას და 81 დეპარტამენტს – თუმცა ყველა დეპარტამენტი არ არის ხელმისაწვდომი ყველა მაღაზიაში.
  ყველაზე მაღალი საშუალო გაყიდვები ჰქონდა დეპარტამენტს 92, თუმცა ყველაზე მაღალი ინდივიდუალური გაყიდვები იყო დეპარტამენტი 72-ში, ძირითადად Thanksgiving-ის კვირაში.

  მაღაზიებს აქვთ ტიპები A, B, C — ტიპი A უდიდესია ზომით (>150,000), და მას აქვს ყველაზე მაღალი საშუალო გაყიდვები.

  ყველაზე მაღალი გაყიდვები დაფიქსირდა Thanksgiving-ის, Christmas-ის და Black Friday-ის კვირებში (კვირები 47–51).

  
  
  ![image](https://github.com/user-attachments/assets/578b19a8-659d-432f-862b-61ae0503caff)


  ![image](https://github.com/user-attachments/assets/5da5436a-f2fd-4149-8cf5-aee4382f5089)


  ![image](https://github.com/user-attachments/assets/16f07a85-c2ca-475d-bbee-dca926a10da0)


  ![image](https://github.com/user-attachments/assets/43305902-de05-446a-bd66-bd0ac2328d52)


  ![image](https://github.com/user-attachments/assets/a1708504-c633-43b8-a3ba-8f1f2f737c34)


  ქვედა გფაფი აჩვენებს გაყიდვებს წლების მიხედვით.

  

  ![image](https://github.com/user-attachments/assets/603177ee-071d-4e42-a131-919f8bc016fb)

  

  კვირების მიხედვით:


  ![image](https://github.com/user-attachments/assets/730193dc-8cbb-40bb-b3ef-989a510be193)



   CPI, Fuel Price, Unemployment, Temperature არ აჩვენებს გამოკვეთილ კორელაციას Weekly_Sales-თან.



   ![image](https://github.com/user-attachments/assets/116c2ee3-530f-4b9b-8b44-e9f84e6ad605)



   ![image](https://github.com/user-attachments/assets/22c91452-e4fb-44ea-84f8-69c5fb72dfde)



   ![image](https://github.com/user-attachments/assets/a9d92048-8f56-49bf-9350-b2f6eca4185a)



   ![image](https://github.com/user-attachments/assets/c2c4b0ed-8aa4-4d05-8b5e-f9d612be6bf6)



# მოდელები 

ეს პროექტი წარმოადგენს XGBoost-ზე დაფუძნებულ დროითი სერიების პროგნოზირების სისტემას, რომელიც შემუშავებულია [Walmart-ის გაყიდვების პროგნოზირების კონკურსისთვის](https://www.kaggle.com/competitions/walmart-recruiting-store-sales-forecasting).

პროექტის მთავარი მიზანია მაქსიმალურად ზუსტი პროგნოზის მიღება `Weekly_Sales` ველისათვის, ისტორიულ გაყიდვებზე, კალენდარულ მოვლენებზე, ეკონომიკურ მაჩვენებლებზე და მაღაზიების შესახებ მეტამონაცემებზე დაყრდნობით.

## მონაცემები 

პროექტი იყენებს კონკურსის ოთხ ძირითად `.csv` ფაილს:

- `train.csv`: ისტორიული ყოველკვირეული გაყიდვები (2010-02-05 — 2012-11-01)
- `features.csv`: ეკონომიკური და კალენდარული მახასიათებლები (ტემპერატურა, საწვავის ფასი, CPI, უმუშევრობა, MarkDown1–5)
- `stores.csv`: მაღაზიის ტიპი და ზომა
- `test.csv`: სატესტო ფაილი

---

 
 ## მოდელი: DLinear (Decomposition Linear)
   ამ პროექტში დაიტესტა DLinear მოდელის არქიტექტურა NeuralForecast ბიბლიოთეკის გამოყენებით.

   ### მოდელის კონფიგურაცია:
   
    * horizon: 28 (forecast horizon in weeks)
    * input_size: 30 (look-back window in weeks)
    * epochs (max_steps): 500
    * batch_size: 64
    * learning_rate: 1e-3

  მოდელი ტრენდება Weights & Biases (W&B) პლატფორმაზე, სადაც ხდება ყველა ექსპერიმენტის დეტალური ლოგირება.

  ### მონაცემთა დამუშავება

    * უარყოფითი Weekly_Sales მნიშვნელობები გადაკეთდა ნულზე
    * შეიქმნა უნიკალური იდენტიფიკატორი Store_Dept ფორმატით
    * Date გადაერქვა ds, ხოლო Weekly_Sales – y, რათა მოდელი თავსებადი ყოფილიყო NeuralForecast ფორმატთან

  ### შეიქმნა DLinearNF კლასი, რომელიც საშუალებას იძლევა:
      * ააგოს DLinear მოდელი მორგებული პარამეტრებით (h და input_size)
      * გახდეს თავსებადი NeuralForecast სტრუქტურასთან
      * გააქტიუროს start_padding_enabled, რათა გაითვალისწინოს მოკლე სერიები
      * გაუშვას ტრენინგი და პროგნოზი fit() და predict() მეთოდებით

![Uploading Screenshot 2025-07-14 at 18.42.00.png…]()



##  მოდელი: PatchTST

### მიმოხილვა

აღნიშნულ ნაწილში აგებული იყო **PatchTST** ტიპის პროგნოზირების pipeline, რომლის მიზანია Walmart-ის ყოველკვირეული გაყიდვების სერიისთვის ლოკალური და გლობალური დროითი პატერნების დაჭერა ყველა Store–Item სერიაზე.

### ძირითადი ლოგიკა

1. **სლაიდინგ ფანჯრის მონაცემთა ფორმატირება:** ყოველი დროითი სერია დაიყო ფიქსირებული სიგრძის შესატანი და სამიზნე ფანჯრებად, რაც საშუალებას აძლევს მოდელს ისწავლოს ჯგუფურად პატჩებზე.
2. **PatchTST არქიტექტურა:** შესატანი სერიები იყოფა გადაფარვად პატჩებად. მოდელი იყენებს self-attention მექანიზმს, რათა ისწავლოს როგორც ერთ პატჩში არსებული ისე სხვადასხვა პატჩის გადაკვეთის დამოკიდებულებები – რაც აუმჯობესებს გრძელვადიანი სტრუქტურების დამუშავებას.
3. **სრული ისტორიის გამოყენება და Hold-Out ტესტი:** ტრენინგი მიმდინარეობს მთლიან ხელმისაწვდომ ისტორიაზე, ხოლო ტესტის ჰორიზონტზე მოდელი აკეთებს პროგნოზს და შედეგები შედარებულია რეალურ გაყიდვებთან.


### შეფასება

- Hold-out ფანჯარაზე გამოითვალა ორი მეტრიკა:
  - **SMAPE (Symmetric Mean Absolute Percentage Error)**
  - **MAE (Mean Absolute Error)**
- თითოეული სერიის შეფასება აგრეგირდა გლობალურ დონეზე საერთო სიზუსტის მაჩვენებლად



## მოდელები: ARIMA და SARIMA

### 1. ARIMA – საწყისი Benchmark

**მიზანი:** 
დროითი მონაცემების საწყისი ანალიზი და მარტივი ბაზისური პროგნოზის შექმნა.

**იმპლემენტაცია:**
- დატვირთული იყო გაყიდვების სერია `(Store, Dept)` წყვილისთვის.
- ყოველ სერიაზე მოხდა **ARIMA (1,1,1)** მოდელის გაშვება `statsmodels` ბიბლიოთეკით.
- შეფასება შესრულდა **MAE (Mean Absolute Error)** მეტრიკით.

** ძირითადი დაკვირვება:**  
მოდელმა კარგად დააფიქსირა ზოგადი ტრენდი, თუმცა ვერ გაუმკლავდა დღესასწაულებს.

---

### 2.  SARIMA – სეზონურობის დამუშავება


** იმპლემენტაცია:**
- გამოყენებული იყო **SARIMAX** მოდელი სეზონური პარამეტრებით: `(0,1,1,52)` – რაც წელიწადის სეზონურ ციკლს მოიცავს.
- დაემატა ცვლადები (`Temperature`, `Fuel_Price`, `CPI`, `Unemployment`).
- შეფასების მეტრიკები და დიაგნოსტიკა დაილოგა **Weights & Biases (W&B)**-ზე.

** ძირითადი დაკვირვება:**  
სეზონურმა კომპონენტებმა და დამატებითმა ფიჩერებმა გააუმჯობესეს პროგნოზი, მაგრამ მოდელის სწავლა თითო სერიაზე ძალიან ნელი იყო.



 ##  მოდელი: LightGBM 


### ეტაპები და მიდგომები

#### საწყისი მოდელი (Baseline)


- **შედეგები:**
  - MAE: ~1,700

---

#### ოპტიმიზირებული საბოლოო მოდელი

** განხორციელებული ცვლილებები:**

1. **მახასიათებლების გამარტივება:**
   - დატოვებულია მხოლოდ მნიშვნელოვანი დღესასწაულები: `Super_Bowl`, `Thanksgiving`
   - დამატებულია `Days_Until_Holiday` – დაეხმაროს მოდელს მოსალოდნელი ზრდის წინასწარ ნახვაში
   -  სტატისტიკებიდან დარჩა მხოლოდ 4-კვირიანი საშუალო

2. **სწავლის აჩქარება:**
   - Boosting ტიპი შეცვლილია `dart`-იდან `gbdt`-ზე 
   - `learning_rate` გაზრდილი 0.03-დან 0.1-მდე და `num_rounds` შემცირდა 2000-დან 800-მდე
   - `num_leaves` შემცირდა → მოდელის კომპლექსობის შემცირება, თუმცა დამატებულია `lambda_l2`, რათა აიცილოს overlearning

3. **დღესასწაულები:**
   
   - დამატებულია `Pre_Holiday_Week` ცვლადი, რათა დაიჭიროს დღემდე გაყიდვების მატება.

---


##  მოდელი: Prophet



### იმპლემენტაცია

- **მონაცემთა წინამზადება:**
  - გაერთიანდა `train.csv`, `features.csv`, `stores.csv` მონაცემები.
  - `Weekly_Sales` გადაერქვა `y`, ხოლო `Date` – `ds`, Prophet-სთვის საჭირო ფორმატში.
  - გამოყენებულია US-ის ოფიციალური დღესასწაულები (`holidays` ბიბლიოთეკით).
  - გაყოფილი იყო მონაცემები 80% ტრენინგზე და 20% ტესტზე დროით სექვენსით.

- **ტრენინგის მახასიათებლები:**
  - ტრენინგი შესრულდა თითოეული `(Store, Dept)` სერიისთვის ინდივიდუალურად.
  - გამოყენებული პარამეტრები:
    - `changepoint_prior_scale`: 0.15
    - `seasonality_prior_scale`: 10.0
    - `holidays_prior_scale`: 10.0
    - `yearly_seasonality`: `True`
    - `weekly_seasonality`: `True`
    - `seasonality_mode`: `"multiplicative"`

- **შეფასების მეტრიკები:**
  - `MAE`, `RMSE` და **WMAE** (სასწორიანი MAE დღესასწაულებზე განსაკუთრებული ყურადღებით).
  - დღესასწაულების კვირებისთვის გამოყენებული იყო წონა 5, დანარჩენებისთვის 1.

- **ლოგირება და შენახვა:**
  - თითოეული მოდელის შედეგები და მეტრიკები დალოგდა **Weights & Biases (W&B)** პლატფორმაზე.
  - მოდელები შენახულია ინდივიდუალურად `.pkl` ფაილებად (`models/prophet_store{X}_dept{Y}.pkl`).
  - ყველა სერიის შედეგები შენახულია CSV ფაილში და ატვირთულია როგორც W&B არტიფაქტი.

---

### ძირითადი დაკვირვებები

- Prophet მოახერხა სეზონური ტენდენციებისა და დღესასწაულების ეფექტების დაჭერა.
- თუმცა, ტრენინგის დრო და რესურსები იზრდებოდა თითო სერიაზე ინდივიდუალური სწავლების გამო.
- **WMAE მნიშვნელობები** აჩვენებდა, რომ მოდელი შედარებით კარგად გაუმკლავდა დღესასწაულების პროგნოზს.

საბოლოოდ, Prophet აღმოჩნდა კარგი კლასიკური მოდელი, რომელიც მინიმალური პარამეტრებით უზრუნველყოფს ინტერპრეტირებად შედეგებს და კარგად ერგება სეზონური გაყიდვების სერიებს.



---
##  მოდელი: XGBoost

მოდელის შეფასება ხდება WMAE მეტრიკით, რომელიც დღესასწაულის კვირებს 5-ჯერ მეტ წონას ანიჭებს, ვიდრე ჩვეულებრივ კვირებს.

## XGBoost_Preprocessing_&_FeatureEngineering Run

მონაცემთა ჩატვირთვა და გაერთიანება: train.csv, features.csv და stores.csv გაერთიანდა raw_df-ში.

თარიღის მახასიათებლების შექმნა: Date სვეტიდან მიღებულია Year, Month, Week, Day, IsHoliday, IsUSHoliday (აშშ-ის ოფიციალური დღესასწაულების მიხედვით).

#### ლაგები და მოძრავი საშუალო:

lag_4 და lag_52 – წინა 4 და 52 კვირის გაყიდვები იგივე Store+Dept-ისთვის

roll_mean_4 და roll_mean_52 – მოძრავი საშუალო (4/52 კვირა, ერთი კვირით გადატანილი leak-ის თავიდან ასაცილებლად)

## კატეგორიული მახასიათებლების კოდირება: Type გარდაიქმნება One-Hot Encoding-ით.

### გამოტოვებული მნიშვნელობების დამუშავება:

MarkDown1-5 → 0 (არ იყო ფასდაკლება)

CPI და Unemployment → შევსება ffill() → bfill() მაღაზიის ჭრილში, შემდეგ მთლიანი მედიანით

## მონაცემთა ქრონოლოგიური გაყოფა:

ტრენინგი: პირველი 80%

ტესტი: ბოლო 20%

## XGBoost_Training_&_Evaluation Run

XGBoost მოდელის გაწვრთნა ხდება შემდეგი პარამეტრებით:

n_estimators: 2500

learning_rate: 0.02

max_depth: 8

subsample: 0.75

colsample_bytree: 0.75

gamma: 0.1

min_child_weight: 5

reg_alpha: 0.1

reg_lambda: 0.1

early_stopping_rounds: 100

eval_metric: "mae"

მოდელი წვრთნიდა და ვალიდირდებოდა wandb.live ლოგინგით.

შეფასება:

პროგნოზები იზომება MAE, RMSE და WMAE მეტრიკებით

სადღესასწაულო კვირების წონა: 5, დანარჩენი კვირები: 1

XGBoost ექსპერიმენტის შედეგები:

Training MAE: 1590.82

Validation MAE: 1398.30

Validation RMSE: 3074.57

Validation WMAE: 1426.32

Best Iteration: 385

მახასიათებლების მნიშვნელობის ანალიზმა გამოავლინა, რომ ყველაზე დიდი გავლენა ჰქონდა lag_52, roll_mean_4, Unemployment, CPI და მაღაზიის ტიპზე (Type_B, Type_C).

მოდელის არტიფაქტი შეინახა JSON ფაილად და აიტვირთა wandb-ში როგორც არტიფაქტი.

ეს ექსპერიმენტი წარმოადგენს ეფექტურ და გამჭვირვალე საფუძველს შემდგომი ტუნინგისა და მოდელის გაუმჯობესებისთვის.



##  მოდელი: N-BEATS (Neural Basis Expansion Analysis for Time Series)


---

### იმპლემენტაცია

- **მოდელის არქიტექტურა:**
  - გამოყენებულია ორ სტეკად გაყოფილი N-BEATS:
    - `Trend` 
    - `Seasonality` 

- **ტექნიკური პარამეტრები:**
  - Lookback ფანჯარა: 52 კვირა  
  - პროგნოზის ფანჯარა: 8 კვირა  
  - Optimizer: `Adam`  
  - Scheduler: ReduceLROnPlateau  
  - Batch size: 32  
  - Epochs: 100 (მაგრამ კოდში 15 -ია ,რადგან ძალიან დიდ ხანს უნდებოდა და შევამცირეთ)
  - Early stopping: patience = 20

- **მონაცემთა დამუშავება:**
  - გაერთიანდა `train.csv`, `features.csv`, `stores.csv`
  - დროითი სერიები შეგროვდა ინდივიდუალურად `Store`-სა და `Dept`-ზე
  - ყველა სერიამ გაიარა სტანდარტულ სკალირებაზე (`StandardScaler`)
  - მონაცემები გარდაიქმნა `TimeSeriesDataset` კლასით PyTorch-ის `DataLoader` ფორმატში
---

### შეფასება

- შეფასება მოხდა შემდეგი მეტრიკებით:
  - **MAE** – საშუალო აბსოლუტური შეცდომა  
  - **RMSE** – ფესვი საშუალო კვადრატული შეცდომისგან  
  - **R² Score** – დეტერმინაციის კოეფიციენტი

| მეტრიკა | მნიშვნელობა |
|--------|-------------|
| MAE    | ~ 1249.79
| RMSE   | ~ 3038.62
| R²     | ~ 0.9755


---

### ძირითადი დასკვნები

- **N-BEATS** არქიტექტურა წარმატებით ასახავს როგორც გრძელვადიან ტენდენციებს, ისე სეზონურ მერყეობებს.
- ტრენინგი სტაბილურია მცირე ეპოქების რაოდენობითაც, რაც აჩენს მოდელის ეფექტურობას.



## მოდელი: Random Forest


###  იმპლემენტაცია

- **მონაცემთა დამუშავება:**
  - გაერთიანდა `train.csv`, `features.csv` და `stores.csv` მონაცემები.
  - წაშლილია არასაიმედო თარიღები და გაუქმებულია დუბლიკატები.
  - დაემატა დროითი და ციკლური ფიჩერები (`Month_sin`, `Week_cos` და სხვ.).

- **ფუნქციური ინჟინერია:**
  - ლაგებისა და მოძრავი საშუალო ფიჩერების დამატება (`Sales_Lag_1`, `Sales_Rolling_4` და სხვ.).
  - Markdown-ებზე დაფუძნებული ველების შექმნა (`MarkDown1_Flag`, `Total_MarkDown`).
  - Store-Dept ინტერაქციის ფიჩერი (`Dept_Store_Interaction`).

- **ტრენინგი:**
  - გამოყენებულია `RandomForestRegressor` sklearn-დან.
  - მხარდაჭერილია ჰიპერპარამეტრების ტიუნინგი `GridSearchCV`-ით.
  - Default მოდელის პარამეტრები:
    - `n_estimators`: 100
    - `max_depth`: 20
    - `max_features`: `'sqrt'`
  - მონაცემთა გაყოფა 80/20 პროპორციით (Chronological Split).

- **შეფასების მეტრიკები:**
  - `MAE`, `RMSE`, `R²` როგორც ტრენინგზე, ისე ტესტზე.
  - დამატებით ითვლება **overfitting მეტრიკები** (`train vs. test` შედარება).

- **ლოგირება:**
  - ყველა პარამეტრი, მეტრიკა და ვიზუალიზაცია აიტვირთება **MLflow**-ზე.
  - ჩაიწერა:
    - Feature Importance
    - Actual vs Predicted გრაფიკები
    - Residual Plot
    - Forecaster არტიფაქტები (Forecast CSV, Feature CSV, Encoders)

---





mlflow:  https://dagshub.com/lkata22/walmart-sales-forecasting-final-project.mlflow/#/experiments/1?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D

wandb:   https://wandb.ai/lkata22-free-university-of-tbilisi-/walmart-sales-forecasting?nw=nwuserlkata22




  
  

  


 






  
